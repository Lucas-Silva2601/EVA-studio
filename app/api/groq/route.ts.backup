import { NextRequest, NextResponse } from "next/server";

/**
 * Rota de API para o Agente Analista.
 * Usa Ollama local (http://localhost:11434) para economizar tokens.
 * O Ollama serve como assistente intermediário que formata pedidos com [EVA_ACTION].
 * O AI Studio (via extensão) executa as tarefas pesadas de geração de código.
 */

const OLLAMA_URL = process.env.OLLAMA_URL ?? "http://localhost:11434";
const OLLAMA_CHAT_ENDPOINT = `${OLLAMA_URL}/api/chat`;
const OLLAMA_MODEL = process.env.OLLAMA_MODEL ?? "llama3.2";
/** Modelo com visão para análise de imagens (ex.: llava). Se não configurado, imagens são ignoradas. */
const OLLAMA_VISION_MODEL = process.env.OLLAMA_VISION_MODEL ?? "llava";

/** Mensagem amigável quando o Ollama não está rodando. */
const OLLAMA_OFFLINE_MSG =
  "O Ollama não está rodando. Inicie-o com: ollama serve (e certifique-se de ter o modelo com ollama pull llama3.2)";

type ChatMessage = { role: "system" | "user" | "assistant"; content: string };
type ContentPart = { type: "text"; text: string } | { type: "image_url"; image_url: { url: string } };
type VisionMessage = { role: "system" | "user" | "assistant"; content: string | ContentPart[] };

interface CallLLMResult {
  content: string;
  finish_reason: string;
}

/** Converte mensagens Groq-style (incl. content array) para formato Ollama. */
function toOllamaMessages(messages: VisionMessage[]): Array<{ role: string; content: string; images?: string[] }> {
  const result: Array<{ role: string; content: string; images?: string[] }> = [];
  for (const m of messages) {
    if (typeof m.content === "string") {
      result.push({ role: m.role, content: m.content });
      continue;
    }
    const parts = m.content as ContentPart[];
    const texts: string[] = [];
    const images: string[] = [];
    for (const p of parts) {
      if (p.type === "text") texts.push(p.text);
      else if (p.type === "image_url" && p.image_url?.url?.startsWith("data:")) {
        const match = p.image_url.url.match(/^data:[^;]+;base64,(.+)$/);
        if (match) images.push(match[1]);
      }
    }
    result.push({ role: m.role, content: texts.join("\n\n").trim() || "Analise a imagem.", images: images.length ? images : undefined });
  }
  return result;
}

/** Chama o Ollama e retorna conteúdo + finish_reason (done_reason). */
async function callOllamaWithMeta(
  messages: ChatMessage[],
  options?: { model?: string; images?: string[] }
): Promise<CallLLMResult> {
  const model = options?.model ?? OLLAMA_MODEL;
  const ollamaMessages: Array<{ role: string; content: string; images?: string[] }> = messages.map((m) => ({
    role: m.role,
    content: m.content,
  }));
  if (options?.images?.length) {
    const lastUserIdx = ollamaMessages.map((m, i) => (m.role === "user" ? i : -1)).filter((i) => i >= 0).pop();
    if (lastUserIdx != null) {
      ollamaMessages[lastUserIdx] = {
        ...ollamaMessages[lastUserIdx],
        images: options.images.slice(0, 5),
      };
    }
  }
  const body = { model, messages: ollamaMessages, stream: false };

  try {
    const res = await fetch(OLLAMA_CHAT_ENDPOINT, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body),
    });

    if (!res.ok) {
      const text = await res.text();
      if (res.status === 404) {
        throw new Error(`Modelo "${model}" não encontrado. Execute: ollama pull ${model}`);
      }
      throw new Error(`Ollama API: ${res.status} - ${text || res.statusText}`);
    }

    const data = (await res.json()) as {
      message?: { content?: string };
      done_reason?: string;
    };
    const content = data.message?.content?.trim() ?? "";
    const finish_reason = data.done_reason ?? "stop";
    return { content, finish_reason };
  } catch (err) {
    const msg = err instanceof Error ? err.message : String(err);
    const isConnectionError =
      msg.includes("ECONNREFUSED") ||
      msg.includes("fetch failed") ||
      msg.includes("Failed to fetch") ||
      msg.includes("net::ERR_CONNECTION_REFUSED") ||
      msg.includes("connect ECONNREFUSED");
    if (isConnectionError) throw new Error(OLLAMA_OFFLINE_MSG);
    if (err instanceof Error) throw err;
    throw new Error(OLLAMA_OFFLINE_MSG);
  }
}

/** Chama o Ollama (wrapper de texto). */
async function callOllama(messages: ChatMessage[]): Promise<string> {
  const { content } = await callOllamaWithMeta(messages);
  return content;
}

/** Chama o Ollama com modelo de visão; fallback para texto se falhar. */
async function callOllamaVision(messages: VisionMessage[]): Promise<CallLLMResult> {
  const ollamaMsgs = toOllamaMessages(messages);
  const lastUser = ollamaMsgs.filter((m) => m.role === "user").pop();
  const images = lastUser?.images ?? [];

  if (images.length > 0) {
    try {
      const textOnly: ChatMessage[] = ollamaMsgs.map((m) => ({ role: m.role as "system" | "user" | "assistant", content: m.content }));
      return await callOllamaWithMeta(textOnly, {
        model: OLLAMA_VISION_MODEL,
        images: images.slice(0, 5),
      });
    } catch {
      const lastUserIdx = ollamaMsgs.map((m, i) => (m.role === "user" ? i : -1)).filter((i) => i >= 0).pop();
      const textOnly: ChatMessage[] = ollamaMsgs.map((m, i) => ({
        role: m.role as "system" | "user" | "assistant",
        content: m.content + (i === lastUserIdx && images.length ? ` [Usuário anexou ${images.length} imagem(ns).]` : ""),
      }));
      return callOllamaWithMeta(textOnly);
    }
  }

  const textOnly: ChatMessage[] = ollamaMsgs.map((m) => ({ role: m.role as "system" | "user" | "assistant", content: m.content }));
  return callOllamaWithMeta(textOnly);
}

/** Verifica se o conteúdo termina com um bloco de código Markdown aberto (sem fechamento). */
function hasOpenCodeBlock(content: string): boolean {
  const trimmed = content.trimEnd();
  if (!trimmed) return false;
  const fences = trimmed.match(/```/g);
  return fences ? fences.length % 2 !== 0 : false;
}

/**
 * Analisa o checklist e retorna a próxima tarefa pendente (ou array de tarefas da fase, se targetPhase for informado).
 * Analista atua como Gerente de Estado.
 */
async function analyzeChecklist(
  checklistContent: string,
  targetPhase?: number
): Promise<string> {
  if (targetPhase != null) {
    const systemPrompt = `Você é o Gerente de Estado da IDE EVA Studio. O checklist pode ser um único arquivo ou uma agregação de docs/fase-1.md, docs/fase-2.md, etc. Cada seção no texto aparece como "## Fase N" (ex.: ## Fase 1, ## Fase 2).

Sua tarefa: retornar um ARRAY JSON com TODAS e SOMENTE as tarefas PENDENTES (linhas que contêm "[ ]") que pertencem à seção "## Fase ${targetPhase}". Inclua subtarefas e subtópicos que estejam sob essa seção até a próxima "## Fase" ou o fim do documento. Ignore completamente tarefas de outras fases e qualquer linha já marcada com "[x]".

REGRAS OBRIGATÓRIAS:
- Retorne APENAS um JSON válido: um array de objetos. Sem markdown, sem blocos de código, sem texto antes ou depois.
- Cada objeto: "taskDescription" (texto completo da tarefa, ex.: "- [ ] Criar componente X"), "taskLine" (a linha EXATA e literal do checklist, para a IDE poder marcar [x] depois), "suggestedFile" (string ou null), "suggestedTech" (string ou null).
- Inclua TODAS as linhas com "[ ]" que estejam na seção ## Fase ${targetPhase}. Ordem: mesma ordem em que aparecem no checklist.
- Se não houver nenhuma tarefa pendente na fase ${targetPhase}, retorne: []`;

    const userPrompt = `Checklist. Retorne um array JSON com TODAS as tarefas pendentes ([ ]) da seção "## Fase ${targetPhase}" (na ordem em que aparecem). Não inclua outras fases.\n\n${checklistContent}`;

    return callOllama([
      { role: "system", content: systemPrompt },
      { role: "user", content: userPrompt },
    ]);
  }

  const systemPrompt = `Você é o Gerente de Estado da IDE EVA Studio. Sua única função é ler o checklist.md e retornar a PRIMEIRA tarefa ainda pendente (primeira linha que contém "[ ]" na ordem do documento). Você NÃO deve repetir tarefas já concluídas ([x]). Nunca retorne uma tarefa que já tem [x] no contexto.
Se o contexto indicar que uma tarefa acabou de ser concluída, você DEVE pular para a próxima. Se houver múltiplas tarefas pendentes, retorne a próxima da lista que NÃO contenha [x].

REGRAS OBRIGATÓRIAS:
- Retorne APENAS um JSON válido, sem markdown, sem texto antes ou depois.
- O JSON deve ter exatamente estes campos (todos strings, exceto suggestedFile/suggestedTech que podem ser null):
  - "taskDescription": texto completo da linha da tarefa (ex.: "- [ ] Criar componente de Login")
  - "taskLine": a linha EXATA e completa do checklist para essa tarefa (cópia literal, para depois marcar [x]). Obrigatório para permitir atualização do arquivo.
  - "suggestedFile": sugestão de caminho de arquivo (ex.: "components/Login.tsx") ou null
  - "suggestedTech": tecnologia sugerida (ex.: "React", "Python") ou null
- Ignore todas as linhas que já têm "[x]". Retorne apenas a PRIMEIRA linha com "[ ]" que encontrar de cima para baixo. Nunca escolha a mesma tarefa se o contexto indicar que foi processada.
- Se não houver nenhuma tarefa pendente, retorne exatamente: {"taskDescription":"","taskLine":"","suggestedFile":null,"suggestedTech":null}`;

  const userPrompt = `Checklist atual (conteúdo do arquivo checklist.md). Retorne o JSON da PRIMEIRA tarefa pendente ([ ]) na ordem do documento:\n\n${checklistContent}`;

  return callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
}

/** Fase 12 (Autocura): Analista analisa o erro e retorna texto + sugestão de correção. A IA NÃO gera código. */
async function reportErrorToAnalyst(payload: {
  taskDescription?: string | null;
  filePath: string;
  errorMessage: string;
  stack?: string | null;
  fileContent?: string | null;
  projectId?: string | null;
}): Promise<string> {
  const { taskDescription, filePath, errorMessage, stack, fileContent, projectId } = payload;
  const proj = projectId?.trim() || "projeto atual";
  const systemPrompt = `Você é o Analista da IDE EVA Studio. O código do usuário falhou ao ser executado (projeto: ${proj}). Você NÃO gera código.

Sua função:
1) Analisar o erro e explicar brevemente a causa.
2) Sugerir em texto o que deve ser alterado (ex.: "Corrija a variável X na linha Y").
3) No final, inclua uma linha "SUGESTÃO DE CORREÇÃO:" seguida de um texto curto descrevendo o que alterar (ex.: "Corrija o arquivo ${filePath}: [resumo do erro e da correção].").

Regras:
- NÃO retorne blocos de código com // FILE:. Apenas análise em texto + a sugestão de correção.
- Se for erro de ambiente (ex.: módulo não instalado), explique como corrigir manualmente.
- O PROMPT PARA O AI STUDIO deve ser em **linguagem natural** (frases), nunca código, JSON ou formato técnico.`;

  let userPrompt = `Arquivo: ${filePath}\nErro: ${errorMessage}${stack ? `\nStack: ${stack.slice(0, 1500)}` : ""}${taskDescription ? `\nTarefa do checklist: ${taskDescription}` : ""}`;
  if (fileContent?.trim()) {
    userPrompt += `\n\n--- Código atual (trecho) ---\n${fileContent.slice(0, 6000)}`;
  }
  userPrompt += "\n\nRetorne: 1) análise do erro; 2) sugestão em texto; 3) linha PROMPT PARA O AI STUDIO: [texto em linguagem natural, sem código].";

  return callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
}

/** Prompt do Analista (Ollama). Apenas assistente: NÃO gera código; a EVA envia implementação para o AI Studio. */
const CHAT_SYSTEM_PROMPT_TEMPLATE = (projectId: string) => `Você é o **assistente** da IDE EVA Studio. Você NÃO é quem implementa código.

ESTILO DE RESPOSTA (OBRIGATÓRIO):
- Seja EXTREMAMENTE BREVE. Responda em no máximo 2 parágrafos curtos.
- Evite repetições, saudações longas ou explicações óbvias.
- Se for apenas confirmar uma ação, use uma única frase.
- O limite de tokens é estrito; respostas longas serão cortadas. Vá direto ao ponto.

MANDATÓRIO: TODO PROJETO APRESENTADO EXIGE UM CHECKLIST
- Para facilitar a criação e organização do projeto, você DEVE SEMPRE começar criando um plano de execução step-by-step.
- Independente do tamanho, se o usuário apresentar uma ideia de projeto, crie o checklist primeiro: docs/fase-1.md, docs/fase-2.md, etc.
- Diga ao usuário que você vai estruturar o projeto em fases para tornar a execução mais fácil e eficiente.

PROJETO EM CONTEXTO: **${projectId}**. Todas as mensagens desta conversa referem-se a este projeto.

PAPEL: APENAS ASSISTENTE — NÃO GERE CÓDIGO
- Quem implementa código é sempre o **AI Studio (Programador)**. A **EVA** envia as tarefas ao AI Studio quando o usuário usa **Executar Fase**, **Implementar Fase N** ou **+AI Studio**.
- **Implementar Fase N:** quando o usuário pedir "implementar fase 1", "executar fase 2", etc., a IDE **automaticamente** envia ao AI Studio **todas** as tarefas pendentes daquela fase em um único prompt. Você só precisa confirmar brevemente (ex.: "Enviando todas as tarefas da Fase N ao AI Studio."). Não liste as tarefas; a IDE já faz isso.
- **Próxima tarefa:** quando o usuário pedir "próxima tarefa" ou "executar" sem mencionar fase, a IDE envia a primeira tarefa pendente do checklist ao AI Studio. Você pode confirmar em uma frase.
- Para pedidos genéricos de site/app/componente: (1) diga que a EVA vai enviar ao AI Studio; (2) sugira usar a ação que **traduz a mensagem em tarefas** e adiciona ao checklist; (3) depois usar **Executar Fase** ou **Implementar Fase N**.

PROMPTS PARA O AI STUDIO (quando o usuário pedir código, ex.: botão, componente, página):
- Use o formato exato: **PROMPT PARA O AI STUDIO:** seguido da instrução. A IDE extrai e envia ao AI Studio.
- OBRIGATÓRIO - SOMENTE TEXTO PURO: O conteúdo após PROMPT PARA O AI STUDIO deve ser exclusivamente linguagem natural (prosa). Descreva o que fazer em frases completas, como se estivesse falando com uma pessoa.
- OBRIGATÓRIO - FORMATO DE SAÍDA: Inclua na sua frase instruções como "retorne o código dentro de blocos Markdown" ou "use markdown para o código". Isso é crucial para a IDE capturar o código.
  - PROIBIDO no PROMPT PARA O AI STUDIO: JSON, chaves e aspas de estrutura de dados, EVA_ACTION, blocos de código, markdown com crases, estruturas técnicas(exceto pedir explicitamente para o AI Studio USAR markdown na resposta).
- Exemplo correto: PROMPT PARA O AI STUDIO: Crie um botão vermelho arredondado em HTML com o texto Clique aqui.Use estilos inline e retorne o código dentro de blocos Markdown.
- Exemplo errado: colocar JSON ou action RUN_COMMAND dentro do PROMPT PARA O AI STUDIO.
- Para citar arquivo ou classe, use texto normal(ex.: no arquivo index.html ou classe btn - vermelho).

O QUE VOCÊ PODE FAZER(assistente):
- Responder dúvidas, explicar o projeto, sugerir próximos passos, ajudar a organizar o checklist.
- Criar estrutura vazia ou arquivos de texto puro(apenas.md, .txt): [EVA_ACTION] { "action": "CREATE_FILE", "path": "...", "content": "..." } e[EVA_ACTION] { "action": "CREATE_DIRECTORY", "path": "..." }.
- Sugerir pacotes: [EVA_ACTION] { "action": "RUN_COMMAND", "command": "npm install ..." }.
- Pedir remoção / movimentação(com aprovação): [EVA_ACTION] { "action": "DELETE_FILE", "path": "..." } ou MOVE_FILE.

RESTRIÇÃO ABSOLUTA - ZERO CÓDIGO E ZERO CARACTERES ESPECIAIS TÉCNICOS:
- Você é PROIBIDO de escrever código (HTML, CSS, JS, JSON, etc.) nas suas respostas.
- Você é PROIBIDO de usar caracteres especiais técnicos como chaves {}, colchetes [], tags <>, crases (backticks), arrobas @, cifrões $, etc., exceto se for estritamente necessário para mencionar um nome de arquivo ou comando npm simples.
- Use APENAS PALAVRAS. Fale como um humano, descrevendo os problemas e soluções em linguagem natural (Português).
- Se precisar mostrar como algo deve ser feito, DESCREVA com palavras, não mostre o código.
- O único lugar onde "código" técnico (como comandos npm ou estrutura de arquivos) é permitido é dentro de [EVA_ACTION]. Fora disso, apenas texto corrido.

PROIBIDO:
- NUNCA use blocos de código (\`\`\`).
- NUNCA mostre exemplos de código no chat.
- NUNCA use CREATE_FILE com código de programação.

Mantenha respostas curtas, objetivas e em Português. Foco no projeto **${projectId}**.`;

/** Chat com o Engenheiro Chefe (Ollama). A IA NÃO gera código: só orquestra. Suporta imagens via llava. */
async function chatWithAnalyst(payload: {
  messages: Array<{ role: "user" | "assistant"; content: string }>;
  projectId: string;
  projectContext?: string | null;
  openFileContext?: { path: string; content: string } | null;
  checklistContext?: string | null;
  images?: Array<{ base64: string; mimeType: string }>;
}): Promise<{ content: string; is_truncated: boolean }> {
  const { messages, projectId, projectContext, openFileContext, checklistContext, images } = payload;

  const systemPrompt = CHAT_SYSTEM_PROMPT_TEMPLATE(projectId);

  const contextParts: string[] = [];
  if (projectContext?.trim()) {
    contextParts.push("--- Contexto do projeto (árvore + conteúdo dos arquivos) ---\n" + projectContext.slice(0, 70_000));
  }
  if (openFileContext?.path && openFileContext?.content != null) {
    contextParts.push(`-- - Arquivo aberto no editor: ${openFileContext.path} ---\n${openFileContext.content.slice(0, 6000)} `);
  }
  if (checklistContext?.trim()) {
    contextParts.push("--- checklist.md ---\n" + checklistContext.slice(0, 8000));
  }
  const injectedContext = contextParts.length > 0
    ? "\n\n" + contextParts.join("\n\n")
    : "";

  const hasImages = images != null && images.length > 0;
  const lastMsg = messages[messages.length - 1];
  const isLastUser = lastMsg?.role === "user";

  if (hasImages && isLastUser && lastMsg) {
    const textWithContext = lastMsg.content + injectedContext;
    const contentParts: ContentPart[] = [{ type: "text", text: textWithContext || "Analise esta(s) imagem(ns)." }];
    for (const img of images.slice(0, 5)) {
      contentParts.push({
        type: "image_url",
        image_url: { url: `data:${img.mimeType}; base64, ${img.base64} ` },
      });
    }
    const visionMessages: VisionMessage[] = [
      { role: "system", content: systemPrompt },
      ...messages.slice(0, -1).map((m) => ({
        role: m.role as "user" | "assistant",
        content: m.content,
      })),
      { role: "user", content: contentParts },
    ];
    const { content, finish_reason } = await callOllamaVision(visionMessages);
    const is_truncated = finish_reason === "length" || hasOpenCodeBlock(content);
    return { content, is_truncated };
  }

  const userMessages: ChatMessage[] = [
    { role: "system", content: systemPrompt },
    ...messages.map((m, i) => {
      const content = m.content + (i === messages.length - 1 && m.role === "user" ? injectedContext : "");
      return { role: m.role as "user" | "assistant", content };
    }),
  ];

  const { content, finish_reason } = await callOllamaWithMeta(userMessages);
  const is_truncated =
    finish_reason === "length" || hasOpenCodeBlock(content);
  return { content, is_truncated };
}

/** Fase 13: Gera código Mermaid (gráfico de dependências/estrutura) a partir da árvore de arquivos. */
async function generateMermaidFromTree(treeText: string): Promise<string> {
  const systemPrompt = `Você é um assistente que gera diagramas Mermaid.js.Dado uma estrutura de pastas e arquivos(texto indentado), retorne APENAS o código Mermaid válido, sem markdown e sem texto antes / depois.

  Regras:
- Use graph LR(left - right) ou graph TD(top - down).Prefira TD para árvores de pastas.
- Pastas como nós retangulares; arquivos como nós com texto do nome.
- Conecte pastas às suas subpastas / arquivos com setas(-->).
- Exemplo mínimo: graph TD, A[raiz]-- > B[pasta1], A-- > C[arquivo.js]
  - Retorne somente o código Mermaid, sem blocos de código ao redor.`;

  const userPrompt = `Gere um diagrama Mermaid que represente esta estrutura de projeto: \n\n${treeText.slice(0, 4000)} `;

  const result = await callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
  return result.trim();
}

/** Fase 11: Traduz ordem do usuário em novas linhas de checklist (para append no arquivo existente). */
async function chatToChecklistTasks(payload: {
  userMessage: string;
  checklistContent?: string | null;
}): Promise<string> {
  const { userMessage, checklistContent } = payload;
  const systemPrompt = `Você é o Agente Analista da IDE EVA Studio.O usuário já tem um arquivo checklist.md no projeto.Sua função é traduzir a ordem ou pedido dele em NOVAS linhas de tarefas que serão ESCRITAS diretamente no final desse arquivo.

  Regras:
- NÃO crie um checklist novo.Retorne APENAS as linhas NOVAS a serem ADICIONADAS ao final do conteúdo existente.
- Formato de cada linha: "- [ ] Descrição da tarefa"(com espaço dentro dos colchetes).
- Inclua o caminho completo do arquivo quando fizer sentido(ex.: "- [ ] Criar src/components/Button.tsx com...").
- Não repita tarefas que já existem no conteúdo atual do checklist.
- Se o usuário não pedir algo que se traduza em tarefas, retorne uma linha: "- [ ] (Nenhuma tarefa gerada: resumo do pedido)" ou sugira uma tarefa coerente.`;

  let userPrompt = `Pedido do usuário: \n${userMessage} `;
  if (checklistContent?.trim()) {
    userPrompt += `\n\n-- - Conteúdo atual do checklist.md(estado do arquivo; adicione apenas linhas novas ao final)---\n${checklistContent.slice(0, 6000)} `;
  }
  userPrompt += "\n\nRetorne apenas as novas linhas de checklist a serem adicionadas ao final do arquivo (uma por linha).";

  return callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
}

/** Pergunta ao Analista: "Qual o nome deste arquivo?" quando o código não indica FILE: na 1ª/2ª linha. */
async function suggestFilename(payload: { content: string }): Promise<string> {
  const { content } = payload;
  const systemPrompt = `Você é o Analista da IDE EVA Studio.O código não indicou o nome do arquivo(não havia FILE: na primeira ou segunda linha).Sua única função é responder com o nome do arquivo que deve ser usado para salvar esse código.

  Regras:
- Retorne APENAS o caminho / nome do arquivo, sem explicação e sem markdown.Ex.: index.html, src / App.jsx, style.css
  - Use a extensão correta conforme o conteúdo: HTML → .html, JavaScript → .js, React → .jsx, CSS → .css, Python → .py, JSON → .json.Nunca use.txt nem nome genérico "file".`;

  const userPrompt = `Qual o nome deste arquivo ? (trecho do código) \n\n${content.slice(0, 3000)} `;

  const result = await callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
  const name = result.trim().replace(/^["']|["']$/g, "").split("\n")[0].trim();
  return name || "index.html";
}

/** Compara código original vs código melhorado pelo AI Studio. Retorna análise em linguagem natural das mudanças e melhorias. */
async function compareCodeChanges(payload: {
  filePath: string;
  originalContent: string;
  newContent: string;
  taskDescription?: string | null;
}): Promise<string> {
  const { filePath, originalContent, newContent, taskDescription } = payload;
  const systemPrompt = `Você é o Analista da IDE EVA Studio.O AI Studio(Programador) melhorou ou alterou um arquivo.Sua função é:

1) Comparar o código ORIGINAL com o código NOVO(vindo do AI Studio).
2) Analisar o que foi mudado: linhas adicionadas, removidas, alteradas.
3) Resumir as melhorias propostas pelo AI Studio em linguagem natural, de forma breve e objetiva.

  Regras:
- Responda SEMPRE em linguagem natural(prosa).NUNCA inclua blocos de código, JSON, markdown técnico ou pseudocódigo.
- Seja direto: liste as principais alterações e o que melhorou(ex.: "O AI Studio adicionou tratamento de erro", "Refatorou o componente para usar hooks").
- Limite a 3 a 5 frases curtas.
- Se não houver mudanças significativas ou o arquivo for novo(original vazio), diga brevemente o que o AI Studio criou ou alterou.`;

  let userPrompt = `Arquivo: ${filePath} \n\n-- - CÓDIGO ORIGINAL-- -\n${originalContent.slice(0, 8000)} \n\n-- - CÓDIGO NOVO(do AI Studio)---\n${newContent.slice(0, 8000)} `;
  if (taskDescription?.trim()) {
    userPrompt += `\n\n-- - Tarefa do checklist-- -\n${taskDescription} `;
  }
  userPrompt += "\n\nCompare e resuma em linguagem natural o que foi mudado e as melhorias propostas pelo AI Studio.";

  return callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
}

/** Valida se o arquivo criado/editado atende à tarefa do checklist. Retorno inclui action MARK_COMPLETE para a IDE marcar [x]. */
async function validateFileAndTask(payload: {
  taskDescription: string;
  fileContent: string;
  fileName?: string;
}): Promise<string> {
  const { taskDescription, fileContent, fileName } = payload;
  const systemPrompt = `Você é o Agente Analista da IDE EVA Studio.Sua função é validar se o conteúdo do arquivo atende à tarefa do checklist.Quando aprovado, a IDE marcará a tarefa como concluída no checklist.md.

  Regras:
- Retorne APENAS um JSON válido, sem markdown e sem texto antes / depois.
- Campos obrigatórios:
- "approved": boolean — true se o arquivo atende à tarefa, false caso contrário
  - "reason": string — motivo breve(ex.: "Componente implementado corretamente" ou "Faltou o botão de submit")
    - "taskLineToMark": string — a linha EXATA do checklist a marcar como[x](cópia da taskDescription com[x] em vez de[]), ou null se não aprovado
      - Quando approved for true, inclua também:
        - "action": "MARK_COMPLETE" — sinal para a IDE executar a marcação no checklist em tempo real`;

  const userPrompt = `Tarefa do checklist: \n${taskDescription} \n\nArquivo${fileName ? `: ${fileName}` : ""} \nConteúdo: \n${fileContent.slice(0, 8000)} \n\nRetorne o JSON de validação(com action: "MARK_COMPLETE" se aprovado).`;

  return callOllama([
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ]);
}

export async function POST(request: NextRequest) {
  try {
    let body: unknown;
    try {
      body = await request.json();
    } catch (parseErr) {
      console.error("[api/groq] POST body parse error", parseErr);
      return NextResponse.json(
        { error: "Body da requisição inválido ou não-JSON." },
        { status: 400 }
      );
    }
    if (body == null || typeof body !== "object") {
      console.warn("[api/groq] POST body vazio ou malformado", { body });
      return NextResponse.json(
        { error: "Body deve ser um objeto JSON." },
        { status: 400 }
      );
    }
    const { action, payload } = body as { action: string; payload?: unknown };
    console.log("Recebendo Ação:", action, "Payload:", !!payload);

    if (!action) {
      return NextResponse.json(
        { error: "Campo 'action' é obrigatório." },
        { status: 400 }
      );
    }

    let result: string;
    let chatResponse: { content: string; is_truncated: boolean } | undefined;

    switch (action) {
      case "analyze": {
        const p = payload as { checklistContent?: string; targetPhase?: number };
        const checklistContent = p?.checklistContent ?? "";
        const targetPhase = p?.targetPhase;
        result = await analyzeChecklist(checklistContent, targetPhase);
        break;
      }
      case "validate": {
        const p = payload as {
          taskDescription?: string;
          fileContent?: string;
          fileName?: string;
        };
        result = await validateFileAndTask({
          taskDescription: p?.taskDescription ?? "",
          fileContent: p?.fileContent ?? "",
          fileName: p?.fileName,
        });
        break;
      }
      case "report_error": {
        const p = payload as {
          taskDescription?: string | null;
          filePath?: string;
          errorMessage?: string;
          stack?: string | null;
          fileContent?: string | null;
          projectId?: string | null;
        };
        result = await reportErrorToAnalyst({
          taskDescription: p?.taskDescription ?? null,
          filePath: p?.filePath ?? "",
          errorMessage: p?.errorMessage ?? "",
          stack: p?.stack ?? null,
          fileContent: p?.fileContent ?? null,
          projectId: p?.projectId ?? null,
        });
        break;
      }
      case "chat": {
        const p = payload as {
          provider?: "ollama";
          messages?: Array<{ role: "user" | "assistant"; content: string }>;
          projectId?: string | null;
          projectContext?: string | null;
          openFileContext?: { path: string; content: string } | null;
          checklistContext?: string | null;
          images?: Array<{ base64: string; mimeType: string }>;
        };
        const chatPayload = {
          messages: p?.messages ?? [],
          projectId: p?.projectId?.trim() || "Projeto não aberto",
          projectContext: p?.projectContext ?? null,
          openFileContext: p?.openFileContext ?? null,
          checklistContext: p?.checklistContext ?? null,
          images: p?.images,
        };
        chatResponse = await chatWithAnalyst({
          ...chatPayload,
          images: p?.images,
        });
        result = chatResponse.content;
        break;
      }
      case "chat_to_tasks": {
        const p = payload as {
          userMessage?: string;
          checklistContent?: string | null;
        };
        result = await chatToChecklistTasks({
          userMessage: p?.userMessage ?? "",
          checklistContent: p?.checklistContent ?? null,
        });
        break;
      }
      case "mermaid": {
        const treeText = (payload as { treeText?: string })?.treeText ?? "";
        result = await generateMermaidFromTree(treeText);
        break;
      }
      case "suggest_filename": {
        const p = payload as { content?: string };
        result = await suggestFilename({ content: p?.content ?? "" });
        break;
      }
      case "compare_code_changes": {
        const p = payload as {
          filePath?: string;
          originalContent?: string;
          newContent?: string;
          taskDescription?: string | null;
        };
        result = await compareCodeChanges({
          filePath: p?.filePath ?? "",
          originalContent: p?.originalContent ?? "",
          newContent: p?.newContent ?? "",
          taskDescription: p?.taskDescription ?? null,
        });
        break;
      }
      default:
        return NextResponse.json(
          { error: `Ação desconhecida: ${action} ` },
          { status: 400 }
        );
    }

    if (chatResponse != null) {
      return NextResponse.json({
        result: chatResponse.content,
        is_truncated: chatResponse.is_truncated,
      });
    }
    return NextResponse.json({ result });
  } catch (err) {
    const message = err instanceof Error ? err.message : "Erro ao chamar a IA";
    console.error("[api/groq]", message, err);
    let status = 500;
    if (message.includes("Ollama") && (message.includes("rodando") || message.includes("não encontrado"))) status = 503;
    return NextResponse.json(
      { error: message },
      { status, headers: { "Content-Type": "application/json" } }
    );
  }
}
